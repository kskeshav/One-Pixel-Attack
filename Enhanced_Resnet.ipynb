{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicCNN(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(BasicCNN, self).__init__()\n",
        "\t\t\"\"\"\n",
        "\t\t\tinput   - (3, 32, 32)\n",
        "\t\t\tblock 1 - (32, 32, 32)\n",
        "\t\t\tmaxpool - (32, 16, 16)\n",
        "\t\t\tblock 2 - (64, 16, 16)\n",
        "\t\t\tmaxpool - (64, 8, 8)\n",
        "\t\t\tblock 3 - (128, 8, 8)\n",
        "\t\t\tmaxpool - (128, 4, 4)\n",
        "\t\t\tblock 4 - (128, 4, 4)\n",
        "\t\t\tavgpool - (128, 1, 1), reshpe to (128,)\n",
        "\t\t\tfc      - (128,) -> (10,)\n",
        "\t\t\"\"\"\n",
        "\t\t# block 1\n",
        "\t\tself.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "\t\tself.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "\t\tself.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "\t\t# block 2\n",
        "\t\tself.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "\t\tself.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "\t\tself.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "\t\t# block 3\n",
        "\t\tself.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\t\tself.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "\t\tself.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "\t\t# block 4\n",
        "\t\tself.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "\t\tself.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "\t\tself.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "\t\tself.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\t\tself.fc = nn.Linear(256, 10)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\n",
        "\t\t# block 1\n",
        "\t\tx = F.relu(self.conv1(x))\n",
        "\t\tx = F.relu(self.bn1(self.conv2(x)))\n",
        "\n",
        "\t\t# maxpool\n",
        "\t\tx = F.max_pool2d(x, 2)\n",
        "\n",
        "\t\t# block 2\n",
        "\t\tx = F.relu(self.conv3(x))\n",
        "\t\tx = F.relu(self.bn2(self.conv4(x)))\n",
        "\n",
        "\t\t# maxpool\n",
        "\t\tx = F.max_pool2d(x, 2)\n",
        "\n",
        "\t\t# block 3\n",
        "\t\tx = F.relu(self.conv5(x))\n",
        "\t\tx = F.relu(self.bn3(self.conv6(x)))\n",
        "\n",
        "\t\t# maxpool\n",
        "\t\tx = F.max_pool2d(x, 2)\n",
        "\n",
        "\t\t# block 4\n",
        "\t\tx = F.relu(self.conv7(x))\n",
        "\t\tx = F.relu(self.bn4(self.conv8(x)))\n",
        "\n",
        "\t\t# avgpool and reshape to 1D\n",
        "\t\tx = self.avgpool(x)\n",
        "\t\tx = x.view(x.size(0), -1)\n",
        "\n",
        "\t\t# fc\n",
        "\t\tx = self.fc(x)\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "class BasicNN(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(BasicNN, self).__init__()\n",
        "\n",
        "\t\tself.fc1 = nn.Linear(28*28, 512)\n",
        "\t\tself.bn1 = nn.BatchNorm1d(512)\n",
        "\n",
        "\t\tself.fc2 = nn.Linear(512, 512)\n",
        "\t\tself.bn2 = nn.BatchNorm1d(512)\n",
        "\n",
        "\t\tself.fc3 = nn.Linear(512, 256)\n",
        "\t\tself.bn3 = nn.BatchNorm1d(256)\n",
        "\n",
        "\n",
        "\t\tself.fc4 = nn.Linear(256, 128)\n",
        "\t\tself.bn4 = nn.BatchNorm1d(128)\n",
        "\n",
        "\t\tself.fc5 = nn.Linear(128, 64)\n",
        "\t\tself.bn5 = nn.BatchNorm1d(64)\n",
        "\n",
        "\n",
        "\n",
        "\t\tself.fc6 = nn.Linear(64, 10)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = F.relu(self.bn1(self.fc1(x)))\n",
        "\n",
        "\t\tx = F.relu(self.bn2(self.fc2(x)))\n",
        "\t\tx = F.relu(self.bn3(self.fc3(x)))\n",
        "\n",
        "\t\tx = F.relu(self.bn4(self.fc4(x)))\n",
        "\t\tx = F.relu(self.bn5(self.fc5(x)))\n",
        "\n",
        "\n",
        "\t\tx = self.fc6(x)\n",
        "\n",
        "\t\treturn x\n",
        "class DenoisingAutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DenoisingAutoEncoder,self).__init__()\n",
        "        self.encoder1 = nn.Sequential(\n",
        "                        nn.Conv2d(3,32,(3,3),padding=1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2,2),\n",
        "                        nn.ZeroPad2d(8),\n",
        "                        nn.Conv2d(32,32,(3,3),padding=1), \n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2,2),\n",
        "                        nn.ZeroPad2d(8)\n",
        "        )\n",
        "        self.encoder2 = nn.Sequential(\n",
        "                        nn.Conv2d(32,64,(3,3),padding=1),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Conv2d(64,128,(3,3),padding=1), \n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "                        nn.ConvTranspose2d(128,64,3,padding=1),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU(),\n",
        "                        nn.ConvTranspose2d(64,32,3,padding=1),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ReLU(),\n",
        "                        nn.ConvTranspose2d(32,3,3,padding=1),\n",
        "                        nn.BatchNorm2d(3),\n",
        "                        nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "                \n",
        "    def forward(self,x):\n",
        "        out = self.encoder1(x)\n",
        "        out = self.encoder2(out)\n",
        "        out = self.decoder(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "    \n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        #self.denoised_layer = denoise()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #out = self.denoised_layer(x)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\t\t\n",
        "\n",
        "class EnhancedResnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EnhancedResnet, self).__init__()\n",
        "        self.denoised_layer = DenoisingAutoEncoder()\n",
        "        self.residualnet = ResNet(Bottleneck, [3,4,6,3])\n",
        "\n",
        "    def forward(self, x):\n",
        "        #out = self.denoised_layer(x)\n",
        "        out = self.denoised_layer(x)\n",
        "        out = self.residualnet(out)\n",
        "        return out\t"
      ],
      "metadata": {
        "id": "fDIy553kAvOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7v2USj-AXSE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "# from models.enhanced_resnet import EnhancedResnet\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models\n",
        "import torch\n",
        "import cv2\n",
        "from scipy.optimize import differential_evolution\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "# from model import BasicCNN\n",
        "from torchvision.utils import save_image\n",
        "# from models.enhanced_resnet import EnhancedResnet\n",
        "from threading import Thread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBCv-PRcAXSL"
      },
      "outputs": [],
      "source": [
        "enm = EnhancedResnet()\n",
        "dnl = torch.load('/content/denoiser.pth')\n",
        "enm.denoised_layer.load_state_dict(dnl['model'])\n",
        "enm.denoised_layer.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJWcRg14AXSO"
      },
      "outputs": [],
      "source": [
        "def plot_figs(imgs):\n",
        "    f = plt.figure(figsize=(8,4))\n",
        "    plt.axis('off')\n",
        "    tot = len(imgs)\n",
        "    i=0\n",
        "    pilTrans = transforms.ToPILImage()\n",
        "    for img in imgs:\n",
        "        i = i+1\n",
        "        f.add_subplot(1,tot, i)\n",
        "        plt.imshow(pilTrans(img))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwSgfGwyAXSQ"
      },
      "outputs": [],
      "source": [
        "def preprocess(img):\n",
        "    img = img.astype(np.float32)\n",
        "    img /= 255.0\n",
        "    img = img.transpose(2, 0, 1)\n",
        "    return img\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "def scale(x, scale=5):\n",
        "    return cv2.resize(x, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr_JO8lpAXSS"
      },
      "outputs": [],
      "source": [
        "def perturb(x):\n",
        "    adv_img = img.copy()\n",
        "    pixs = np.array(np.split(x, len(x)/5)).astype(int)\n",
        "    loc = (pixs[:, 0], pixs[:,1])\n",
        "    val = pixs[:, 2:]\n",
        "    adv_img[loc] = val\n",
        "    return adv_img\n",
        "def optimize(x):\n",
        "    adv_img = perturb(x)\n",
        "    inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
        "    out = model(inp)\n",
        "    prob = softmax(out.data.numpy()[0])\n",
        "    return prob[pred_orig]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnriP19tAXSU"
      },
      "outputs": [],
      "source": [
        "tr = datasets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "pred_adv = 0\n",
        "prob_adv = 0\n",
        "def callback(x, convergence):\n",
        "    global pred_adv, prob_adv\n",
        "    adv_img = perturb(x)\n",
        "    inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
        "    out = model(inp)\n",
        "    prob = softmax(out.data.numpy()[0])\n",
        "    pred_adv = np.argmax(prob)\n",
        "    prob_adv = prob[pred_adv]\n",
        "    if pred_adv != pred_orig and prob_adv >= 0.9:\n",
        "        print('Attack successful..')\n",
        "        print('Prob [%s]: %f' %(cifar10_class_names[pred_adv], prob_adv))\n",
        "        print()\n",
        "        return True\n",
        "    else:\n",
        "        print('Prob [%s]: %f' %(cifar10_class_names[pred_orig], prob[pred_orig]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRsMfAcUAXSX"
      },
      "source": [
        "# Select Image from the Dataset to attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMTDJSsQAXSZ"
      },
      "outputs": [],
      "source": [
        "idx = 423\n",
        "fname = \"/content/adv_img_\"+str(idx)+\".png\"\n",
        "d = 1\n",
        "iters = 600\n",
        "popsize = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3tvo4cDAXSb"
      },
      "outputs": [],
      "source": [
        "tnsr,lb = tr.__getitem__(idx)\n",
        "save_image(tnsr,\"/home/testing.png\")\n",
        "image_path = \"/home/testing.png\" #images/airplane.png(id-438) or car.png adv-3.png adv-37.png adv-158.png 221.png\n",
        "cifar10_class_names = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOhx8E4eAXSd"
      },
      "outputs": [],
      "source": [
        "orig = cv2.imread(image_path)[..., ::-1]\n",
        "orig = cv2.resize(orig, (32, 32))\n",
        "img = orig.copy()\n",
        "shape = orig.shape\n",
        "model = BasicCNN()\n",
        "# saved = torch.load(\"/cifar10_basiccnn.pth.tar\")\n",
        "# model.load_state_dict(saved['state_dict'])\n",
        "model.eval()\n",
        "inp = Variable(torch.from_numpy(preprocess(img)).float().unsqueeze(0))\n",
        "prob_orig = softmax(model(inp).data.numpy()[0])\n",
        "pred_orig = np.argmax(prob_orig)\n",
        "print('Prediction of the image before attack: %s' %(cifar10_class_names[pred_orig]))\n",
        "#print('Probability: %f' %(prob_orig[pred_orig]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR6Ixo4JAXSg"
      },
      "outputs": [],
      "source": [
        "bounds = [(0, shape[0]-1), (0, shape[1]), (0, 255), (0, 255), (0, 255)] * d\n",
        "result = differential_evolution(optimize, bounds, maxiter=iters, popsize=popsize, tol=1e-5, callback=callback)\n",
        "adv_img = perturb(result.x)\n",
        "inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
        "out = model(inp)\n",
        "prob = softmax(out.data.numpy()[0])\n",
        "print('Prob [%s]: %f --> Prob[%s]: %f' %(cifar10_class_names[pred_orig], prob_orig[pred_orig], cifar10_class_names[pred_adv], prob_adv))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShkYvirLAXSh"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2.imwrite(fname, adv_img[..., ::-1]) #images/adv_img_airplane.png\n",
        "cv2_imshow(scale(adv_img[..., ::-1]))\n",
        "while True:\n",
        "    key = cv2.waitKey(33)\n",
        "    if key == 27 or key == 32:\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "637nGFwoAXSi"
      },
      "source": [
        "Adding autoencoding layers to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-SwN9ClAXSj"
      },
      "outputs": [],
      "source": [
        "orig = cv2.imread(fname)[..., ::-1] #images/adv_img_airplane.png or cat.png\n",
        "orig = preprocess(orig)\n",
        "inp = Variable(torch.from_numpy(orig)).float().unsqueeze(0)\n",
        "out = enm.denoised_layer(inp)\n",
        "z = torch.reshape(out,(3,32,32))\n",
        "print(\"Denoised Image:\")\n",
        "plot_figs([z])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNenTRErAXSj"
      },
      "outputs": [],
      "source": [
        "inp = Variable(z).float().unsqueeze(0)\n",
        "out = model(inp)\n",
        "prob = softmax(out.data.numpy()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyiTGeIwAXSk"
      },
      "outputs": [],
      "source": [
        "n = cifar10_class_names[np.argmax(prob)]\n",
        "#v = np.amax(prob)\n",
        "print('Prediction of the image before attack: %s' %(cifar10_class_names[pred_orig]))\n",
        "#print('Probability: %f' %(prob_orig[pred_orig]))\n",
        "#if n==cifar10_class_names[pred_orig]:\n",
        "print('With denoised layers, image is predicted as %s'%(n))\n",
        "#else:\n",
        "#    v = prob[pred_orig]\n",
        "#    print('Confidence in original class is restored to: %f'%(v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TI7naLQAXSq"
      },
      "outputs": [],
      "source": [
        "n = cifar10_class_names[np.argmax(prob)]\n",
        "v = np.amax(prob)\n",
        "print('Prediction before attack: %s' %(cifar10_class_names[pred_orig]))\n",
        "print('Probability: %f' %(prob_orig[pred_orig]))\n",
        "if n==cifar10_class_names[pred_orig]:\n",
        "    print('With denoised layers, image is predicted as %s with confidence %f'%(n,v))\n",
        "else:\n",
        "    v = prob[pred_orig]\n",
        "    print('Confidence in original class is restored to: %f'%(v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXeOQTtUAXSq"
      },
      "outputs": [],
      "source": [
        "n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYDh8LiiAXSr"
      },
      "outputs": [],
      "source": [
        "v"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2IU94Bot3u62"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}