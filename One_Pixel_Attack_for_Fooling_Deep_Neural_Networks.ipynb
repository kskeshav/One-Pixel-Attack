{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puKxI8A1cXT3"
      },
      "source": [
        "# One Pixel Attack for Fooling Deep Neural Networks\n",
        "An implementation of the procedure described in https://arxiv.org/abs/1710.08864."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHr_Xj_GcXT5"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kHoODb8cXT7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "!pip install tensorboardcolab\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from pathlib import Path\n",
        "# from tensorboardX import SummaryWriter\n",
        "from torchvision import datasets, transforms, models\n",
        "from tqdm import tqdm\n",
        "logdir = './logs/func'\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "sns.set()\n",
        "sns.set_style(\"dark\")\n",
        "sns.set_palette(\"muted\")\n",
        "sns.set_color_codes(\"muted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sghc8O6wcXT9"
      },
      "source": [
        "### CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUjRQkuDcXT_"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {'num_workers': 4}\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtmL0JpbcXUB"
      },
      "source": [
        "## Train CIFAR VGG16 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU5IBKjkcXUC"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-jObmmkcXUC"
      },
      "outputs": [],
      "source": [
        "cifar_model = models.vgg16(pretrained=True, init_weights=False)\n",
        "cifar_model.classifier = nn.Sequential(\n",
        "        nn.Linear(25088, 2048),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(2048, 2048),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(2048, 10),\n",
        "    )\n",
        "cifar_model = cifar_model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHD1ZX6tcXUE"
      },
      "source": [
        "### Dataloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vcqg7KvRcXUG"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "TRAIN_COUNT = 40_000\n",
        "VAL_COUNT = 10_000\n",
        "TEST_COUNT = 10_000\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.ToTensor()\n",
        "\n",
        "train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "train_set = torch.utils.data.dataset.Subset(train_set, range(0,TRAIN_COUNT))\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, **LOADER_KWARGS)\n",
        "\n",
        "val_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=test_transform)\n",
        "val_set = torch.utils.data.dataset.Subset(val_set, range(TRAIN_COUNT,TRAIN_COUNT+VAL_COUNT))\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, **LOADER_KWARGS)\n",
        "\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, **LOADER_KWARGS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxrJJx7PcXUI"
      },
      "source": [
        "### Test and Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "70CTVRCOcXUK"
      },
      "outputs": [],
      "source": [
        "def test(epoch=None, is_validation=False):\n",
        "    cifar_model.eval()\n",
        "    loader = val_loader if is_validation else test_loader\n",
        "    test_loss = 0\n",
        "    test_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            outputs = cifar_model(inputs)\n",
        "            test_loss += F.cross_entropy(outputs, targets, size_average=False).item()\n",
        "            test_correct += outputs.max(1)[1].eq(targets).sum().item()\n",
        "    # if is_validation:\n",
        "    #     # writer.add_scalar('logs/val_loss', test_loss/len(loader.dataset), epoch)\n",
        "    #     # writer.add_scalar('logs/val_acc', test_correct/len(loader.dataset), epoch)\n",
        "    # else:\n",
        "    print(\"Test Accuracy: {}/{}\".format(test_correct, len(loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwhc7751cXUL"
      },
      "source": [
        "### Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K6NwuLTZcXUL"
      },
      "outputs": [],
      "source": [
        "#optimizer = optim.Adam(cifar_model.classifier.parameters())\n",
        "optimizer = optim.Adam(cifar_model.parameters())\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    cifar_model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_correct = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cifar_model(inputs)\n",
        "        loss = F.cross_entropy(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_correct = outputs.max(1)[1].eq(targets).sum().item()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_correct += batch_correct\n",
        "        # writer.add_scalar('logs/train_loss', loss.item(), epoch*len(train_loader) + batch_idx)\n",
        "        # writer.add_scalar('logs/train_acc', batch_correct / targets.size(0), epoch*len(train_loader) + batch_idx)\n",
        "    test(epoch, is_validation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQkFWkkCcXUN"
      },
      "source": [
        "### Train Model and Store Weights (or Load Weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QtCT_cTcXUN"
      },
      "outputs": [],
      "source": [
        "TRAIN_EPOCHS = 20\n",
        "WEIGHTS_PATH = Path(\"./vgg_cifar_weights.pt\")\n",
        "\n",
        "if WEIGHTS_PATH.is_file():\n",
        "    cifar_model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
        "    print(\"Loaded weights from file:\", WEIGHTS_PATH)\n",
        "else:\n",
        "    for epoch in range(TRAIN_EPOCHS):\n",
        "        train(epoch)\n",
        "    torch.save(cifar_model.state_dict(), WEIGHTS_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnSZgTYrcXUO"
      },
      "source": [
        "### Test Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-yv-mYPcXUO"
      },
      "outputs": [],
      "source": [
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoS8HNBXcXUP"
      },
      "source": [
        "## Attack CIFAR Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDirFdNQcXUP"
      },
      "outputs": [],
      "source": [
        "CIFAR_LABELS = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def show(img):\n",
        "    npimg = img.cpu().numpy()\n",
        "    plt.figure(figsize=(1,1))\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n",
        "def tell(img, label, model, target_label=None):\n",
        "    print(\"True Label:\", CIFAR_LABELS[label], label)\n",
        "    print(\"Prediction:\", CIFAR_LABELS[model(img.unsqueeze(0)).max(-1)[1]], model(img.unsqueeze(0)).max(-1)[1][0].item())\n",
        "    print(\"Label Probabilities:\", F.softmax(model(img.unsqueeze(0)).squeeze(), dim=0))\n",
        "    print(\"True Label Probability:\", F.softmax(model(img.unsqueeze(0)).squeeze(), dim=0)[label].item())\n",
        "    if target_label is not None:\n",
        "        print(\"Target Label Probability:\", F.softmax(model(img.unsqueeze(0)).squeeze(), dim=0)[target_label].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y500yiKqcXUQ"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZBS6XYMcXUQ"
      },
      "outputs": [],
      "source": [
        "test_img, test_label = test_set[20]\n",
        "test_img = test_img.to(DEVICE)\n",
        "show(test_img)\n",
        "tell(test_img, test_label, cifar_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OLTPKDfcXUR"
      },
      "source": [
        "### Perturbation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGEEzJu6cXUR"
      },
      "outputs": [],
      "source": [
        "def perturb(p, img):\n",
        "    # Elements of p should be in range [0,1]\n",
        "    img_size = img.size(1) # C x _H_ x W, assume H == W\n",
        "    p_img = img.clone()\n",
        "    xy = (p[0:2].copy() * img_size).astype(int)\n",
        "    xy = np.clip(xy, 0, img_size-1)\n",
        "    rgb = p[2:5].copy()\n",
        "    rgb = np.clip(rgb, 0, 1)\n",
        "    p_img[:,xy[0],xy[1]] = torch.from_numpy(rgb)\n",
        "    return p_img\n",
        "\n",
        "def visualize_perturbation(p, img, label, model, target_label=None):\n",
        "    p_img = perturb(p, img)\n",
        "    print(\"Perturbation:\", p)\n",
        "    show(p_img)\n",
        "    tell(p_img, label, model, target_label)\n",
        "\n",
        "visualize_perturbation(np.array([0.6,0.6,0,0,0.75]), test_img, test_label, cifar_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZBVnzRGcXUS"
      },
      "source": [
        "### Untargeted and Targeted Attacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbgebv_UcXUT"
      },
      "outputs": [],
      "source": [
        "def evaluate(candidates, img, label, model):\n",
        "    preds = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, xs in enumerate(candidates):\n",
        "            p_img = perturb(xs, img)\n",
        "            preds.append(F.softmax(model(p_img.unsqueeze(0)).squeeze(), dim=0)[label].item())\n",
        "    return np.array(preds)\n",
        "\n",
        "def evolve(candidates, F=0.5, strategy=\"clip\"):\n",
        "    gen2 = candidates.copy()\n",
        "    num_candidates = len(candidates)\n",
        "    for i in range(num_candidates):\n",
        "        x1, x2, x3 = candidates[np.random.choice(num_candidates, 3, replace=False)]\n",
        "        x_next = (x1 + F*(x2 - x3))\n",
        "        if strategy == \"clip\":\n",
        "            gen2[i] = np.clip(x_next, 0, 1)\n",
        "        elif strategy == \"resample\":\n",
        "            x_oob = np.logical_or((x_next < 0), (1 < x_next))\n",
        "            x_next[x_oob] = np.random.random(5)[x_oob]\n",
        "            gen2[i] = x_next\n",
        "    return gen2\n",
        "\n",
        "def attack(model, img, true_label, target_label=None, iters=100, pop_size=400, verbose=True):\n",
        "    # Targeted: maximize target_label if given (early stop > 50%)\n",
        "    # Untargeted: minimize true_label otherwise (early stop < 5%)\n",
        "    candidates = np.random.random((pop_size,5))\n",
        "    candidates[:,2:5] = np.clip(np.random.normal(0.5, 0.5, (pop_size, 3)), 0, 1)\n",
        "    is_targeted = target_label is not None\n",
        "    label = target_label if is_targeted else true_label\n",
        "    fitness = evaluate(candidates, img, label, model)\n",
        "    \n",
        "    def is_success():\n",
        "        return (is_targeted and fitness.max() > 0.5) or ((not is_targeted) and fitness.min() < 0.05)\n",
        "    \n",
        "    for iteration in range(iters):\n",
        "        # Early Stopping\n",
        "        if is_success() or iteration>1:\n",
        "            break\n",
        "        if verbose and iteration%10 == 0: # Print progress\n",
        "            print(\"Target Probability [Iteration {}]:\".format(iteration), fitness.max() if is_targeted else fitness.min())\n",
        "        # Generate new candidate solutions\n",
        "        new_gen_candidates = evolve(candidates, strategy=\"resample\")\n",
        "        # Evaluate new solutions\n",
        "        new_gen_fitness = evaluate(new_gen_candidates, img, label, model)\n",
        "        # Replace old solutions with new ones where they are better\n",
        "        successors = new_gen_fitness > fitness if is_targeted else new_gen_fitness < fitness\n",
        "        candidates[successors] = new_gen_candidates[successors]\n",
        "        fitness[successors] = new_gen_fitness[successors]\n",
        "    for i in range(5):\n",
        "      best_idx = fitness.argmax() if is_targeted else fitness.argmin()\n",
        "      best_solution = candidates[best_idx]\n",
        "      best_score = fitness[best_idx]\n",
        "\n",
        "      fitness = np.delete(fitness, best_idx)\n",
        "      candidates = np.delete(candidates,best_idx, axis = 0)\n",
        "    \n",
        "      if verbose:\n",
        "        visualize_perturbation(best_solution, img, true_label, model, target_label)\n",
        "    return is_success() #,  best_solution, best_score\n",
        "\n",
        "# Untargeted attack\n",
        "_ = attack(cifar_model, test_img, test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSeORd2PSYo_"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "dict = {\n",
        "    \"airplane\":[], \n",
        "    \"automobile\" :[],\n",
        "    \"bird\" :[],\n",
        "    \"cat\" :[],\n",
        "    \"deer\" :[],\n",
        "    \"dog\" :[],\n",
        "    \"frog\" :[],\n",
        "    \"horse\" :[],\n",
        "    \"ship\" :[],\n",
        "    \"truck\" :[],\n",
        "}\n",
        "r = list(range(200))\n",
        "random.shuffle(r)\n",
        "x = []\n",
        "y = []\n",
        "for i in r:\n",
        "    test_img, test_label = test_set[i]\n",
        "    if test_label == 5:\n",
        "      test_img = test_img.to(DEVICE)\n",
        "      _, sol, score = attack(cifar_model, test_img, test_label)\n",
        "      if(score<0.5):\n",
        "        x.append(sol[0])\n",
        "        y.append(sol[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "386Hc8SdWjwo"
      },
      "outputs": [],
      "source": [
        "plt.plot(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPTguk9YcXUT"
      },
      "outputs": [],
      "source": [
        "# Targeted attack\n",
        "# This is much harder/costlier than an untargeted attack\n",
        "# For time reasons, targeted attacks below use 20 iterations\n",
        "targeted_results = {}\n",
        "for idx in range(len(CIFAR_LABELS)):\n",
        "    if idx != test_label:\n",
        "        targeted_results[idx] = attack(cifar_model, test_img, test_label, target_label=idx, iters=20, verbose=False)\n",
        "        print(CIFAR_LABELS[idx], idx, targeted_results[idx][0], targeted_results[idx][2])\n",
        "    else:\n",
        "        print(CIFAR_LABELS[idx], idx, \"True Label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGTpusTzOW6m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}